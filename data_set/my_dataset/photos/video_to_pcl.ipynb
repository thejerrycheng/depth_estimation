{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a test using feature extraction and ego-motion to get the point cloud depth information of each frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load video\n",
    "video = cv2.VideoCapture('path_to_video')\n",
    "\n",
    "# Initialize SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Process video frames\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Extract SIFT features\n",
    "    keypoints, descriptors = sift.detectAndCompute(frame, None)\n",
    "\n",
    "    # Feature matching with previous frame (using FLANN, for example)\n",
    "    # ...\n",
    "\n",
    "    # Estimate camera motion (Ego-motion)\n",
    "    # ...\n",
    "\n",
    "    # Triangulate to find depth\n",
    "    # ...\n",
    "\n",
    "# Visualization using Plotly\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x_coords, y=y_coords, z=z_coords, mode='markers')])\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
